{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# if os.getcwd().split('/')[-1] != 'scripts':\n",
    "#     %cd scripts\n",
    "#     print('Changed directory to scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "#from model import Model\n",
    "from at_model import Model\n",
    "#from multi_at_model import Model\n",
    "from train_model import TrainModel\n",
    "from data_module import DataModule\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Loaded: (207, 207)\n",
      "Feature Matrix Loaded: (2017, 207)\n"
     ]
    }
   ],
   "source": [
    "# Load adjacency matrix\n",
    "adj_path = \"./data/los_adj.csv\"\n",
    "adj_df = pd.read_csv(adj_path, header=None)\n",
    "print(\"Adjacency Matrix Loaded:\", adj_df.shape)\n",
    "\n",
    "# Load feature matrix\n",
    "feat_path = \"./data/los_speed.csv\"\n",
    "feat_df = pd.read_csv(feat_path, header=None)\n",
    "print(\"Feature Matrix Loaded:\", feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_pre_len(pre_len, feat_path, adj_path):\n",
    "    print(f\"Training model with pre_len = {pre_len}...\")\n",
    "\n",
    "    # Initialize DataModule\n",
    "    data_module = DataModule(\n",
    "        feat_path=feat_path,\n",
    "        adj_path=adj_path,\n",
    "        batch_size=32,\n",
    "        seq_len=12,\n",
    "        pre_len=pre_len,\n",
    "        scaling_method=\"minmax\"\n",
    "    )\n",
    "\n",
    "    # Model parameters\n",
    "    input_dim = data_module.feat.shape[1]\n",
    "    hidden_dim = 24\n",
    "    output_dim = pre_len\n",
    "    num_nodes = data_module.adj.shape[0]\n",
    "    adj = torch.from_numpy(data_module.adj).to('cpu')\n",
    "\n",
    "    # Initialize model and training wrapper\n",
    "    model = Model(\n",
    "        adj=adj,\n",
    "        seq_len=data_module.seq_len,\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=output_dim,\n",
    "        num_nodes=num_nodes,\n",
    "        num_stacks=1,\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "    )\n",
    "    train_model = TrainModel(\n",
    "        model=model,\n",
    "        pre_len=pre_len,\n",
    "        feat_max_val=data_module.feat_max_val,\n",
    "        feat_min_val=data_module._feat_min_val,\n",
    "        learning_rate= 7e-4,\n",
    "        scaling_method=\"minmax\",\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,  # Increased from 5\n",
    "        mode=\"min\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=500,\n",
    "        callbacks=[early_stopping, pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")],\n",
    "        logger=True,\n",
    "        gradient_clip_val=2,\n",
    "        accelerator=\"cpu\",\n",
    "        accumulate_grad_batches=4,  # Larger effective batch size\n",
    "        min_epochs=15,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(train_model, data_module)\n",
    "\n",
    "    # Log metrics\n",
    "    final_metrics = trainer.logged_metrics\n",
    "    print(final_metrics)\n",
    "    rmse = final_metrics.get(\"val_rmse\", torch.tensor(float(\"nan\"))).item()\n",
    "    mae = final_metrics.get(\"val_mae\", torch.tensor(float(\"nan\"))).item()\n",
    "\n",
    "    train_loss = trainer.callback_metrics['train_loss'].item()\n",
    "    val_loss = trainer.callback_metrics['val_loss'].item()\n",
    "\n",
    "    print(f\"Completed training for pre_len = {pre_len}: RMSE = {rmse:.4f}, MAE = {mae:.4f}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return data_module, train_model, model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/akshat/Developer/ML_WORK/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/akshat/Developer/ML_WORK/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model       | Model             | 6.6 K  | train\n",
      "1 | rmse_metric | MeanSquaredError  | 0      | train\n",
      "2 | mae_metric  | MeanAbsoluteError | 0      | train\n",
      "----------------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n",
      "25        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with pre_len = 3...\n",
      "Feature matrix shape: (2016, 207)\n",
      "Adjacency matrix shape: (207, 207)\n",
      "Original feature range: 1.0 70.0\n",
      "Scaled feature range: 0.0, 1.0\n",
      "Shape of tensor 0 in train dataset: torch.Size([1597, 12, 207])\n",
      "Shape of tensor 1 in train dataset: torch.Size([1597, 3, 207])\n",
      "Shape of tensor 0 in validation dataset: torch.Size([389, 12, 207])\n",
      "Shape of tensor 1 in validation dataset: torch.Size([389, 3, 207])\n",
      "Epoch 0: 100%|██████████| 50/50 [00:07<00:00,  6.53it/s, v_num=26, train_loss_step=0.918, val_loss=38.10, val_rmse=44.30, val_mae=35.20, train_loss_epoch=0.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 38.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [00:06<00:00,  7.66it/s, v_num=26, train_loss_step=0.927, val_loss=36.80, val_rmse=42.60, val_mae=33.90, train_loss_epoch=0.837]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.326 >= min_delta = 0.0. New best score: 36.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 50/50 [00:06<00:00,  7.70it/s, v_num=26, train_loss_step=0.827, val_loss=34.70, val_rmse=41.20, val_mae=31.30, train_loss_epoch=0.756]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 2.140 >= min_delta = 0.0. New best score: 34.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 50/50 [00:06<00:00,  7.57it/s, v_num=26, train_loss_step=0.607, val_loss=28.90, val_rmse=33.70, val_mae=26.30, train_loss_epoch=0.752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 5.763 >= min_delta = 0.0. New best score: 28.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 50/50 [00:06<00:00,  7.25it/s, v_num=26, train_loss_step=0.612, val_loss=24.70, val_rmse=28.30, val_mae=22.80, train_loss_epoch=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 4.198 >= min_delta = 0.0. New best score: 24.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 50/50 [00:06<00:00,  7.90it/s, v_num=26, train_loss_step=0.813, val_loss=17.90, val_rmse=20.90, val_mae=16.60, train_loss_epoch=0.620]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 6.812 >= min_delta = 0.0. New best score: 17.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 50/50 [00:06<00:00,  7.27it/s, v_num=26, train_loss_step=0.573, val_loss=17.60, val_rmse=19.40, val_mae=16.50, train_loss_epoch=0.584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.291 >= min_delta = 0.0. New best score: 17.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 50/50 [00:06<00:00,  7.52it/s, v_num=26, train_loss_step=0.559, val_loss=16.60, val_rmse=19.70, val_mae=15.50, train_loss_epoch=0.579]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.976 >= min_delta = 0.0. New best score: 16.626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 50/50 [00:06<00:00,  7.38it/s, v_num=26, train_loss_step=0.540, val_loss=16.30, val_rmse=19.00, val_mae=15.10, train_loss_epoch=0.536]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.318 >= min_delta = 0.0. New best score: 16.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  52%|█████▏    | 26/50 [00:03<00:03,  7.84it/s, v_num=26, train_loss_step=0.531, val_loss=16.70, val_rmse=18.60, val_mae=15.60, train_loss_epoch=0.548]"
     ]
    }
   ],
   "source": [
    "def generate_predictions_and_plots(data_module, train_model, model, pre_len):\n",
    "    print(\"Generating Predictions...\")\n",
    "\n",
    "    val_loader = data_module.val_dataloader()\n",
    "    actual_values, predicted_values = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            x, y = batch\n",
    "            x, y = x.to(train_model.device), y.to(train_model.device)\n",
    "            y_pred = train_model(x)\n",
    "            actual_values.append(y.cpu().numpy())\n",
    "            predicted_values.append(y_pred.cpu().numpy())\n",
    "\n",
    "    actual_values = np.concatenate(actual_values, axis=0)\n",
    "    predicted_values = np.concatenate(predicted_values, axis=0)\n",
    "    predicted_values = predicted_values[:, :actual_values.shape[1], :]\n",
    "\n",
    "    scaling_method = data_module.scaling_method\n",
    "    if scaling_method == 'minmax':\n",
    "        min_val, max_val = data_module._feat_min_val, data_module._feat_max_val\n",
    "        def inverse_scale(data, min_val, max_val):\n",
    "            return data * (max_val - min_val) + min_val\n",
    "        actual_values = inverse_scale(actual_values, min_val, max_val)\n",
    "        predicted_values = inverse_scale(predicted_values, min_val, max_val)\n",
    "    elif scaling_method == 'std':\n",
    "        scaler = data_module.scaler\n",
    "        actual_values = scaler.inverse_transform(actual_values.reshape(-1, actual_values.shape[-1])).reshape(actual_values.shape)\n",
    "        predicted_values = scaler.inverse_transform(predicted_values.reshape(-1, predicted_values.shape[-1])).reshape(predicted_values.shape)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaling method. Choose 'minmax' or 'std'.\")\n",
    "\n",
    "    if actual_values.shape != predicted_values.shape:\n",
    "        raise ValueError(f\"Shapes mismatch: {actual_values.shape} vs {predicted_values.shape}\")\n",
    "\n",
    "    timestamps = np.arange(actual_values.shape[0])\n",
    "    node_indices_to_plot = [11, 44, 112, 32]\n",
    "    save_directory = \"./prediction_plots\"\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    print(\"Generating and saving plots...\")\n",
    "    for node_index in node_indices_to_plot:\n",
    "        plt.figure()\n",
    "        plt.plot(timestamps, actual_values[:, 0, node_index], label='Actual')\n",
    "        plt.plot(timestamps, predicted_values[:, 0, node_index], label='Predicted')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Node {node_index} - Actual vs Predicted')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_directory, f'node_{node_index}_comparison.png'))\n",
    "        plt.close()\n",
    "    print(f\"Plots saved to: {save_directory}\")\n",
    "\n",
    "for pre_len in [3]:\n",
    "    data_module, train_model, model, trainer = train_model_with_pre_len(pre_len, feat_path, adj_path)\n",
    "    generate_predictions_and_plots(data_module, train_model, model, pre_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
